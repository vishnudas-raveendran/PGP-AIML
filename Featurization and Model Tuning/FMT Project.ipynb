{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ae249b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c8b4b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = pd.read_csv('signal-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6f8effd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>...</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>...</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>...</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time        0        1          2          3       4      5  \\\n",
       "0  2008-07-19 11:55:00  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   \n",
       "1  2008-07-19 12:32:00  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0   \n",
       "2  2008-07-19 13:17:00  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   \n",
       "3  2008-07-19 14:43:00  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0   \n",
       "4  2008-07-19 15:22:00  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0   \n",
       "\n",
       "          6       7       8  ...       581     582     583     584      585  \\\n",
       "0   97.6133  0.1242  1.5005  ...       NaN  0.5005  0.0118  0.0035   2.3630   \n",
       "1  102.3433  0.1247  1.4966  ...  208.2045  0.5019  0.0223  0.0055   4.4447   \n",
       "2   95.4878  0.1241  1.4436  ...   82.8602  0.4958  0.0157  0.0039   3.1745   \n",
       "3  104.2367  0.1217  1.4882  ...   73.8432  0.4990  0.0103  0.0025   2.0544   \n",
       "4  100.3967  0.1235  1.5031  ...       NaN  0.4800  0.4766  0.1045  99.3032   \n",
       "\n",
       "      586     587     588       589  Pass/Fail  \n",
       "0     NaN     NaN     NaN       NaN         -1  \n",
       "1  0.0096  0.0201  0.0060  208.2045         -1  \n",
       "2  0.0584  0.0484  0.0148   82.8602          1  \n",
       "3  0.0202  0.0149  0.0044   73.8432         -1  \n",
       "4  0.0202  0.0149  0.0044   73.8432         -1  \n",
       "\n",
       "[5 rows x 592 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1e8094e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.rename(columns={\"Pass/Fail\": \"result\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d65fd9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 592)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d0e5d8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time       object\n",
       "0         float64\n",
       "1         float64\n",
       "2         float64\n",
       "3         float64\n",
       "           ...   \n",
       "586       float64\n",
       "587       float64\n",
       "588       float64\n",
       "589       float64\n",
       "result      int64\n",
       "Length: 592, dtype: object"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "be66768c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time       0\n",
       "0          6\n",
       "1          7\n",
       "2         14\n",
       "3         14\n",
       "          ..\n",
       "586        1\n",
       "587        1\n",
       "588        1\n",
       "589        1\n",
       "result     0\n",
       "Length: 592, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e3118c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = sdata.select_dtypes([np.int64, np.float64]).columns\n",
    "impute = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "sdata[numeric_cols] = impute.fit_transform(sdata[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7dce0777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "         ..\n",
       "586       0\n",
       "587       0\n",
       "588       0\n",
       "589       0\n",
       "result    0\n",
       "Length: 592, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5e0596c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>71.9005</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>...</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>...</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>...</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2008-10-16 15:13:00</td>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>...</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2008-10-16 20:49:00</td>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2008-10-17 05:26:00</td>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>1.4616</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2008-10-17 06:01:00</td>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>...</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.4616</td>\n",
       "      <td>...</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time        0        1          2          3       4  \\\n",
       "0     2008-07-19 11:55:00  3030.93  2564.00  2187.7333  1411.1265  1.3602   \n",
       "1     2008-07-19 12:32:00  3095.78  2465.14  2230.4222  1463.6606  0.8294   \n",
       "2     2008-07-19 13:17:00  2932.61  2559.94  2186.4111  1698.0172  1.5102   \n",
       "3     2008-07-19 14:43:00  2988.72  2479.90  2199.0333   909.7926  1.3204   \n",
       "4     2008-07-19 15:22:00  3032.24  2502.87  2233.3667  1326.5200  1.5334   \n",
       "...                   ...      ...      ...        ...        ...     ...   \n",
       "1562  2008-10-16 15:13:00  2899.41  2464.36  2179.7333  3085.3781  1.4843   \n",
       "1563  2008-10-16 20:49:00  3052.31  2522.55  2198.5667  1124.6595  0.8763   \n",
       "1564  2008-10-17 05:26:00  2978.81  2379.78  2206.3000  1110.4967  0.8236   \n",
       "1565  2008-10-17 06:01:00  2894.92  2532.01  2177.0333  1183.7287  1.5726   \n",
       "1566  2008-10-17 06:07:00  2944.92  2450.76  2195.4444  2914.1792  1.5978   \n",
       "\n",
       "          5         6       7       8  ...       581     582     583     584  \\\n",
       "0     100.0   97.6133  0.1242  1.5005  ...   72.2889  0.5005  0.0118  0.0035   \n",
       "1     100.0  102.3433  0.1247  1.4966  ...  208.2045  0.5019  0.0223  0.0055   \n",
       "2     100.0   95.4878  0.1241  1.4436  ...   82.8602  0.4958  0.0157  0.0039   \n",
       "3     100.0  104.2367  0.1217  1.4882  ...   73.8432  0.4990  0.0103  0.0025   \n",
       "4     100.0  100.3967  0.1235  1.5031  ...   72.2889  0.4800  0.4766  0.1045   \n",
       "...     ...       ...     ...     ...  ...       ...     ...     ...     ...   \n",
       "1562  100.0   82.2467  0.1248  1.3424  ...  203.1720  0.4988  0.0143  0.0039   \n",
       "1563  100.0   98.4689  0.1205  1.4333  ...   72.2889  0.4975  0.0131  0.0036   \n",
       "1564  100.0   99.4122  0.1208  1.4616  ...   43.5231  0.4987  0.0153  0.0041   \n",
       "1565  100.0   98.7978  0.1213  1.4622  ...   93.4941  0.5004  0.0178  0.0038   \n",
       "1566  100.0   85.1011  0.1235  1.4616  ...  137.7844  0.4987  0.0181  0.0040   \n",
       "\n",
       "          585     586     587     588       589  result  \n",
       "0      2.3630  0.0205  0.0148  0.0046   71.9005    -1.0  \n",
       "1      4.4447  0.0096  0.0201  0.0060  208.2045    -1.0  \n",
       "2      3.1745  0.0584  0.0484  0.0148   82.8602     1.0  \n",
       "3      2.0544  0.0202  0.0149  0.0044   73.8432    -1.0  \n",
       "4     99.3032  0.0202  0.0149  0.0044   73.8432    -1.0  \n",
       "...       ...     ...     ...     ...       ...     ...  \n",
       "1562   2.8669  0.0068  0.0138  0.0047  203.1720    -1.0  \n",
       "1563   2.6238  0.0068  0.0138  0.0047  203.1720    -1.0  \n",
       "1564   3.0590  0.0197  0.0086  0.0025   43.5231    -1.0  \n",
       "1565   3.5662  0.0262  0.0245  0.0075   93.4941    -1.0  \n",
       "1566   3.6275  0.0117  0.0162  0.0045  137.7844    -1.0  \n",
       "\n",
       "[1567 rows x 592 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are no invalid characters other than numeric\n",
    "sdata[~sdata.applymap(np.isreal).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4a1671bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sdata.drop(columns=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3794d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sdata.drop(columns=['result']).copy()\n",
    "y = sdata['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "12b320b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Remove outliers if any\n",
    "#sdata = sdata.copy()\n",
    "Q1 = X.quantile(0.25)\n",
    "Q3 = X.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# Replace every outlier on the lower side by the lower whisker\n",
    "for i, j in zip(np.where(X < Q1 - 1.5 * IQR)[0], np.where(X < Q1 - 1.5 * IQR)[1]): \n",
    "    \n",
    "    whisker  = Q1 - 1.5 * IQR\n",
    "    X.iloc[i,j] = whisker[j]\n",
    "    \n",
    "    \n",
    "#Replace every outlier on the upper side by the upper whisker    \n",
    "for i, j in zip(np.where(X > Q3 + 1.5 * IQR)[0], np.where(X > Q3 + 1.5 * IQR)[1]):\n",
    "    \n",
    "    whisker  = Q3 + 1.5 * IQR\n",
    "    X.iloc[i,j] = whisker[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "03fbb0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>...</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2     3     4     5     6     7     8     9  ...   580  \\\n",
       "result                                                              ...         \n",
       "-1.0    1463  1463  1463  1463  1463  1463  1463  1463  1463  1463  ...  1463   \n",
       " 1.0     104   104   104   104   104   104   104   104   104   104  ...   104   \n",
       "\n",
       "         581   582   583   584   585   586   587   588   589  \n",
       "result                                                        \n",
       "-1.0    1463  1463  1463  1463  1463  1463  1463  1463  1463  \n",
       " 1.0     104   104   104   104   104   104   104   104   104  \n",
       "\n",
       "[2 rows x 590 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Check for target imbalance\n",
    "sdata.groupby([\"result\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d454abb5",
   "metadata": {},
   "source": [
    "We have a imbalanced dataset, having pass values less than 10% value count than failed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "23ad4c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before UpSampling, counts of label '-1': 1463\n",
      "Before UpSampling, counts of label '1': 104 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before UpSampling, counts of label '-1': {}\".format(sum(sdata['result']==-1)))\n",
    "print(\"Before UpSampling, counts of label '1': {} \\n\".format(sum(sdata['result']==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "916eb97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fb1940a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "over = SMOTE(sampling_strategy=0.5) #create 50% extra datapoints of majority class so 104+0.5*1463=~835\n",
    "under = RandomUnderSampler(sampling_strategy=0.8) #reduce from the majority class to match data points 50% more than the minority class\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X_bal, y_bal = pipeline.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1e3f3497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset:\n",
      "After Up and down Sampling, counts of label '-1': 913\n",
      "After Up and down Sampling, counts of label '1': 731 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Balanced dataset:\")\n",
    "print(\"After Up and down Sampling, counts of label '-1': {}\".format(sum(y_bal==-1)))\n",
    "print(\"After Up and down Sampling, counts of label '1': {} \\n\".format(sum(y_bal==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3fdbefe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "test_valid_split_size = 0.5 #the test-validation is split into equal parts of the remaining 20%\n",
    "X_train,X_rem,y_train,y_rem = train_test_split(X_bal,y_bal,train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "cf641a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem,train_size=test_valid_split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e3597fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (1315, 590)\n",
      "y_train : (1315,)\n",
      "X_valid : (164, 590)\n",
      "y_valid : (164,)\n",
      "X_test: (165, 590)\n",
      "y_test : (165,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"X_train : {X_train.shape}\"), print(f\"y_train : {y_train.shape}\")\n",
    "print(f\"X_valid : {X_valid.shape}\"), print(f\"y_valid : {y_valid.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\"), print(f\"y_test : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7cd736",
   "metadata": {},
   "source": [
    "#####  Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "72ae5faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9939393939393939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "scr = clf.score(X_test, y_test)\n",
    "print(f\"Accuracy {scr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1ba7ce32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEKCAYAAACIZDejAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaMElEQVR4nO3debwU1Z338c/3XnALIiiLrBENUXFHFLeo0UcDjjPGLdFokiHxMSQaX3FGozNj4qiZR6NmXCKGMMYYoxGjYsQEl+gkQcWFxRXcEBcQFVDEBaPey+/5o+pi097bXRdud9ft+337qterq+r0qV+D/jynTp1TigjMzLq6hloHYGaWB06GZmY4GZqZAU6GZmaAk6GZGeBkaGYGOBmaWScj6WpJSyQ91cZ5Sbpc0nxJT0gamaVeJ0Mz62yuAcaUOD8WGJ5uJwK/yFKpk6GZdSoRMR14q0SRw4BrI/EQ0EvSgHL1duuoAGtF3TYMrbdxrcOwdthl26G1DsHa4eWXX2LZsmValzoae342oumDTGXjg6Vzgb8XHJoUEZPacblBwMKC/UXpsddKfanzJ8P1Nmb9rb9S6zCsHR54+Ipah2DtsPfoUetcRzR9kPm/078/NuHvEbEuF20tcZedd9zpk6GZdQYCVe2u3CJgSMH+YGBxuS/5nqGZVZ6AhsZs27qbCnwjHVXeA1gRESW7yOCWoZlVi9bptmNBNboB2B/oI2kRcDbQHSAiJgLTgEOA+cBKYFyWep0MzawKOq6bHBHHljkfwEntrdfJ0Myqo4NahpXiZGhmlSeqOYCyVpwMzawK5JahmRnQUSPFFeNkaGZVUNXnDNeKk6GZVZ5wN9nMDHDL0MzM3WQzM0i6yY0eQDEz8z1DMzN3k83MWrhlaGaGW4ZmZsjT8czMEp6OZ2bmARQzs4S7yWbW5Xk9QzMzcDfZzKyFB1DMzPA9QzOz5DlDd5PNzNwyNDMDkJOhmXV1yar/ToZm1tVJqMHJ0MzMLUMzM3AyNDMDnAzNzNIRlFoHUZqToZlVnJBbhmZmAA0NnoFiZuaWoZmZ7xmamaXy3jLMdyfezOpCywBKli1TfdIYSc9Kmi/pzFbObyLpdkmPS5oraVy5Ot0yNLOq6KjpeJIagQnAQcAiYKakqRExr6DYScC8iPhHSX2BZyVdHxEftVWvW4ZmVnmiI1uGuwPzI2JBmtwmA4cVlQlgYyUV9gDeAppKVeqWoZlVRTvuGfaRNKtgf1JETCrYHwQsLNhfBIwuquMKYCqwGNgY+GpErCp1USdDM6uKdiTDZRExqlRVrRyLov0vAY8BBwBbAX+WdF9EvNNWpe4mm1nFdfAAyiJgSMH+YJIWYKFxwJRIzAdeBLYpVamToZlVhzJu5c0EhksaJmk94BiSLnGhV4ADAST1B7YGFpSq1N1kM6s8ddx0vIhoknQycBfQCFwdEXMljU/PTwTOA66R9GRydc6IiGWl6nUyNLOq6MiHriNiGjCt6NjEgs+LgYPbU6eToZlVR74noPieYd78/EfH8dxd5zNj8r/XOhTL6J4Z89jtyHMZefh/csk1d9c6nNzqyBkolVCVZChpG0kPSvpQ0mklyg2T9LCk5yXdmN4c7VJu+ONDHHXKhFqHYRk1N6/i9At/z02XfY+Hfn8Wt9w9m2cWvFbrsHInayKs+2RI8vT3KcDFZcr9FLgkIoYDy4FvVzqwvJnx6Assf2dlrcOwjGbPfYkth/Rhi8F9WK97N444aCTT/vZErcPKJSdDICKWRMRM4OO2yqTTZg4Abk4P/Qb4cuWjM1t7ry1dwaD+vVfvD+zfm9eWrqhhRPmlBmXaaiVPAyibAW9HRMv8wUUk024+RdKJwIkAdO9RleDMWhNRPPEBcr5SVc3kfQmvPCXDLFNskoPJPMVJAA0b9Wu1jFk1DOzXi1ffWL56f/Eby9m8zyY1jCinlP9kWLFusqSTJD2WbgMzfGUZ0EtSS4JubYqNWa6MHPFZXnhlKS+/uoyPPm5iyp/nMHbfHWsdVu6IpMWcZauVirUMI2ICyZpjWcuHpL8AR5EsyfNN4LYKhZdbV/3kn9l71+Fs1qsHT/3xPC6YNI3rpj5Y67CsDd26NXLhD7/CkadMoLk5OO6f9mDbrQbUOqwc8tvxAJC0OTAL6AmskvQDYEREvCNpGnBC+sT4GcBkST8BHgV+VY348uSEs66pdQjWTgfvvR0H771drcPIvYYaDo5kUZVkGBGvk3R7Wzt3SMHnBSQLN5pZPalxFziLPA2gmFmdEm4ZmpkBbhmamQH5f7TGydDMKs/3DM3MkmX/O2px10pxMjSzqnDL0MwM3zM0M/M9QzMzaJmbnO9s6GRoZlWR81zoZGhm1eEZKGZmnWA9QydDM6u4lvUM88zJ0MyqwOsZmpkBbhmamYE8gGJm5ucMzcxaOBmameF7hmZmgFuGZmZeqMHMDFoWd813NnQyNLOqaMh50zDf63CbWd2Qsm3Z6tIYSc9Kmi/pzDbK7C/pMUlzJf2tXJ1uGZpZxakDF2qQ1AhMAA4CFgEzJU2NiHkFZXoBVwJjIuIVSf3K1euWoZlVRYOybRnsDsyPiAUR8REwGTisqMzXgCkR8QpARCwpV2mbLUNJPweirfMRcUqWqM3MoF3T8fpImlWwPykiJhXsDwIWFuwvAkYX1fF5oLukvwIbA5dFxLWlLlqqmzyrxDkzs8xEMqKc0bKIGFWmumLFDbduwK7AgcCGwIOSHoqI59qqtM1kGBG/WePq0mci4v0SAZqZtakDn6xZBAwp2B8MLG6lzLI0Z70vaTqwE9BmMix7z1DSnpLmAU+n+ztJurKdwZtZV6ZkPcMsWwYzgeGShklaDzgGmFpU5jbgC5K6SdqIpBv9dKlKs4wmXwp8qeViEfG4pH2zRGxm1qKjHjOMiCZJJwN3AY3A1RExV9L49PzEiHha0p3AE8Aq4KqIeKpUvZkerYmIhUUZu3ltfoSZdU2iYx+6johpwLSiYxOL9i8CLspaZ5ZkuFDSXkCkTdJTKNPcNDMrlvfpeFmeMxwPnEQynP0qsHO6b2aWSdbZJ7WcsVe2ZRgRy4DjqhCLmdWxTj83WdKWkm6XtFTSEkm3SdqyGsGZWf1Qxq1WsnSTfwf8HhgADARuAm6oZFBmVn868NGaisiSDBURv42IpnS7jhLT9MzMiiWjyR02N7kiSs1N3jT9+Jd0iZzJJEnwq8CfqhCbmdULde7FXWeTJL+WX/CdgnMBnFepoMys/nTad6BExLBqBmJm9aulm5xnmWagSNoeGAFs0HKs3HI4ZmaFOm3LsIWks4H9SZLhNGAscD/gZGhmmeU7FWYbTT6KZE2w1yNiHMkyOOtXNCozqysSNDYo01YrWbrJH0TEKklNknoCSwA/dG1m7dLpu8nArPTlKv9DMsL8HvBIJYMys/qT81yYaW7y99KPE9P1wXpGxBOVDcvM6olQ7ucml3roemSpcxExpzIhmVndqfGKNFmUahn+rMS5AA7o4FjWys7bDuW+B39e6zCsHXrv8YNah2Dt8OEzC8sXyqDT3jOMiC9WMxAzq18CGjtrMjQz60h1MQPFzGxdORmaWZeXLOmf72yYZaVrSTpe0o/T/aGSdq98aGZWT/K+nmGW6XhXAnsCx6b77wITKhaRmdWlTv9CKGB0RIyU9ChARCxPXxlqZpaJgG457yZnSYYfS2okXepfUl+SN9SbmWWW81yYKRleDtwK9JP0XySr2JxV0ajMrK5InXg6XouIuF7SbJJlvAR8OSKernhkZlZXcp4LMy3uOhRYCdxeeCwiXqlkYGZWX+rhOcM/8cmLoTYAhgHPAttVMC4zqyOCmi7cmkWWbvIOhfvpajbfaaO4mdmn1fgZwizaPQMlIuZI2q0SwZhZ/VLO34KS5Z7hvxTsNgAjgaUVi8jM6k69vCp044LPTST3EG+pTDhmVq86dTJMH7buERGnVykeM6tTeV+oodSy/90ioqnU8v9mZlkkrwqtdRSllQqv5Q14j0maKunrko5o2aoRnJnVj4Z0Fkq5LQtJYyQ9K2m+pDNLlNtNUrOko8rVmeWe4abAmyTvPGl53jCAKZmiNrMuryMHUNLbdxOAg4BFwExJUyNiXivlfgrclaXeUsmwXzqS/BSfJMEW0Y7Yzcw6cjre7sD8iFiQ1KvJwGHAvKJy3ycZ7M30KGCpZNgI9IBWHw5yMjSzdhAN2Z8z7CNpVsH+pIiYVLA/CCh8Zd8iYPQaV5MGAYeT9GjXORm+FhHnZqnEzKwU0a6W4bKIGFWmumLFDbRLgTMiojnrKHapZJjvcXAz6zwE3TruQcNFwJCC/cHA4qIyo4DJaSLsAxwiqSki/tBWpaWS4YFrF6eZ2Zra2TIsZyYwXNIw4FXgGOBrhQUiYtjqa0vXAH8slQih9Evk31qHYM3M1tBRi7umzz+fTDJK3AhcHRFzJY1Pz09cm3r9qlAzq4qOnIASEdOAaUXHWk2CEfHPWep0MjSzihPZXsVZS06GZlZ56rhucqU4GZpZxSUzUJwMzcxy/6yek6GZVUXOG4ZOhmZWDeq86xmamXUUjyabmaU8gGJmpk687L+ZWUdxN9nMLOWWoZkZfs7QzAwBjW4Zmpn5oWszM0Ao5x1lJ0Mzqwq3DM2sy0sercl3NnQyNLPKk1uGZmaAp+OZmaWLu9Y6itKcDM2sKjyabGZG/u8Z5n3udF2498F5jD76PHY78hwu+83dnzofEfzbz25mtyPPYd/jzufxZxauPnfKedezzZh/Y59j/1+rdV9x3b30Gf193nz7vYrF39UduMc2PHLjvzP7pv/gB18/8FPnN9l4Q357wbe4/7ofcs+vTmXbLTdffe47X9mXGdefwYzfncH4r+5XzbBzRxn/qZWqJUNJV0taIumpNs5L0uWS5kt6QtLIasVWSc3Nqzjjopu48dLv8sDk/2DK3bN5dsFra5S5Z8Y8FixcwiM3/5j/PvMYTr/wxtXnjjl0NDde+r1W6371jeX87ZFnGLx574r+hq6soUFcdNpRHH3qL9nj2As48uCRbL1F/zXK/Os3D+LJ519ln+Mv5LvnXs/5px4BwLZbbs43D9uTA7/133zh6xfxpX1GsOWQPrX4GTXXcs8wy1Yr1WwZXgOMKXF+LDA83U4EflGFmCpuzryXGTa4D1sM6sN63btx+EG7csf0J9coc8f0J/nK2N2RxKgdhrHi3Q94fdkKAPba5XP07rlRq3WfdckUzj75sNyvBtKZ7TrisyxYtIyXF7/Jx03NTPnzoxyy7w5rlNl6WH+mz3oOgOdfXsLQAZvSd9MefH6L/syc+xIffPgxzc2reGDOCxy63461+Bm1J9GQcauVqiXDiJgOvFWiyGHAtZF4COglaUB1oquc15a8zcD+n7TcBvbrxWtL316zzNK3GfSpMitK1nvH9CcZ0HcTtv/84A6N19Y0oO8mvLpk+er9xUveZkDfTdYo89Tzizl0/50AGDliKEM2783Avr14esHr7LXzVvTuuREbrt+dg/YawaD+vaoZfq4o41YreRpAGQQsLNhflB57rbigpBNJWo8MGTq0KsGtrWjlWHFLLuLTpUr9S7Hy7x9xyTV3cfPlJ61bcFZWaw2VKPpbvfTaezj/X45g+rWnM++FxTzx3Ks0N6/iuZfe4LLf3sutP/8u76/8iLnPv0pT06oqRZ4vfm9y+7T2J9VaLiEiJgGTAEbuOqrVMnkxsF8vFr+xZsti8z6bFJXpzavFZYpaH4VeWrSMVxa/yX7HX7C6/AHfuJC7f30a/Tfr2cG/oGtbvGQFg/qt2Wp/fek7a5R5d+WHnPyTG1bvP37rj3l58ZsAXHf7w1x3+8MA/Gj8P7C4qFfQleQ7FeZrNHkRMKRgfzCwuEaxdJhdth3KgoVLeXnxMj76uIlb/zybMUX3nMZ8YXt+f8cjRASznnyRnj02+FTCLDTicwN55s7zefQP5/DoH85hYL9e/O+1P3QirIA5T7/CVkP6MHTApnTv1sgRB+3CHfetOQbYs8eGdO/WCMA3DtuDGY++wLsrPwSgT+8eAAzu34tD99+Rm++eU90fkCc57yfnqWU4FThZ0mRgNLAiIj7VRe5sunVr5ILTjuboU65k1arga/+4B9tsOYBfT7kfgHFH7MNBe2/HPTPmsduR57LhBt25/EfHr/7+/z3r1zwwZz5vvf0eOxz6I8448RCO/6c9a/Vzupzm5lX88OJbuOWy8TQ2NHD9Hx/mmRdfZ9zhewHw61tnsPUW/fnF2cfR3LyKZ196ne//1+TV37/2/HH03uQzNDU1c/rFN7Pi3Q9q9VNqLu/dZLV2v6oiF5JuAPYH+gBvAGcD3QEiYqKSG2lXkIw4rwTGRcSscvWO3HVU3PfgzEqFbRXQZ69Tax2CtcOHT9/AqvffWKdMtu0Ou8S1t/01U9ndt+o1OyJGrcv11kbVWoYRcWyZ8wF4RMCsXuW7YZirbrKZ1ankdmC+s6GToZlVXidYzzBPo8lmVsc6cjBZ0hhJz6bTd89s5fxx6bTeJyTNkLRTuTrdMjSzKlCHTRuV1AhMAA4ieSRvpqSpETGvoNiLwH4RsVzSWJLnkkeXqtfJ0MyqogO7ybsD8yNiQVKvJpNM512dDCNiRkH5h0ieWy7J3WQzq7isXeQ0X/aRNKtgO7Gouram7rbl28Ad5WJ0y9DMqiN7y3BZmecMM0/dlfRFkmS4T7mLOhmaWVV04KM1mabuStoRuAoYGxFvlqvU3WQzqwop25bBTGC4pGGS1gOOIZnOW3AtDQWmAF+PiOeyVOqWoZlVXgc+ZxgRTZJOBu4CGoGrI2KupPHp+YnAj4HNgCvTUeymclP8nAzNrCo6cgZKREwDphUdm1jw+QTghPbU6WRoZhUn8j8DxcnQzKoi57nQydDMqiTn2dDJ0MyqIu+LuzoZmllV5DsVOhmaWbXkPBs6GZpZxXlxVzMz6BSLuzoZmllV5DwXOhmaWTV03OKuleJkaGZVkfNc6GRoZpXXnveb1IqToZlVR86zoZOhmVWFH60xM8P3DM3MQNDgZGhmBnm/aehkaGYV58VdzcxSOc+FToZmVh1uGZqZgafjmZmBu8lmZu15QXzNOBmaWVV4BoqZGeS+n+xkaGZVkfNc6GRoZtUgvyrUzKwzzEBpqHUAZmZ54JahmVVF3luGToZmVhV+tMbMzA9dm5l1jgEUJ0Mzqwp3k83MyH/L0I/WmFlVKOOWqS5pjKRnJc2XdGYr5yXp8vT8E5JGlqvTydDMqqODsqGkRmACMBYYARwraURRsbHA8HQ7EfhFuXqdDM2s4gQ0SJm2DHYH5kfEgoj4CJgMHFZU5jDg2kg8BPSSNKBUpZ3+nuGjc2Yv67F+w8u1jqMC+gDLah2EtUu9/p19dl0rmDNn9l0bdlefjMU3kDSrYH9SREwq2B8ELCzYXwSMLqqjtTKDgNfauminT4YR0bfWMVSCpFkRMarWcVh2/jtrW0SM6cDqWms+xlqUWYO7yWbW2SwChhTsDwYWr0WZNTgZmllnMxMYLmmYpPWAY4CpRWWmAt9IR5X3AFZERJtdZKiDbnIdm1S+iOWM/86qICKaJJ0M3AU0AldHxFxJ49PzE4FpwCHAfGAlMK5cvYoo2Y02M+sS3E02M8PJ0MwMcDKsOUnbSHpQ0oeSTitRbpikhyU9L+nG9MaxVZmkqyUtkfRUG+fbPQ3M8sHJsPbeAk4BLi5T7qfAJRExHFgOfLvSgVmrrgFKPTPX7mlglg9OhjUWEUsiYibwcVtlJAk4ALg5PfQb4MuVj86KRcR0kv+BtaXd08AsH5wMO4fNgLcjoindb5laZPnT1jQwyzknw86h3VOLrGb8d9VJORnWgKSTJD2WbgMzfGUZSXer5SH5slOLrGbaPQ3M8sHJsAYiYkJE7JxuZf9DieTJ+L8AR6WHvgncVskYba21exqY5YNnoNSYpM2BWUBPYBXwHjAiIt6RNA04ISIWS9qSZN22TYFHgeMj4sNaxd1VSboB2J9kua43gLOB7pBMA0sHu64gGXFeCYyLiFmt12Z54mRoZoa7yWZmgJOhmRngZGhmBjgZmpkBToZmZoCTYd2T1Jw+3P2UpJskbbQOdV0j6aj081WtvKu2sOz+kvZai2u8JH36LWptHS8q8147r/WfpVYKsq7FybD+fZA+3L098BEwvvBk+kLudouIEyJiXoki+wPtToZmteJk2LXcB3wubbX9RdLvgCclNUq6SNLMdA2+78DqtfmukDRP0p+Afi0VSfqrpFHp5zGS5kh6XNK9krYgSbqnpq3SL0jqK+mW9BozJe2dfnczSXdLelTSL2l9bu8aJP1B0mxJcyWdWHTuZ2ks90rqmx7bStKd6Xfuk7RNh/xpWl3xC6G6iHRe81jgzvTQ7sD2EfFimlBWRMRuktYHHpB0N7ALsDWwA9AfmAdcXVRvX+B/gH3TujaNiLckTQTei4iL03K/I1mP8X5JQ0le5rMtyQyO+yPiXEn/QLIGYDnfSq+xITBT0i0R8SbwGWBORPyrpB+ndZ9M8qKm8RHxvKTRwJUkS6KZreZkWP82lPRY+vk+4Fck3ddHIuLF9PjBwI4t9wOBTUgWJ90XuCEimoHFkv63lfr3AKa31BURba3193+AEclsNQB6Sto4vcYR6Xf/JGl5ht90iqTD089D0ljfJJnOeGN6/DpgiqQe6e+9qeDa62e4hnUxTob174OI2LnwQJoU3i88BHw/Iu4qKncI5ZefUoYykNyS2TMiPmgllsxzQiXtT5JY94yIlZL+CmzQRvFIr/t28Z+BWTHfMzRIuqzfldQdQNLnJX0GmA4ck95THAB8sZXvPgjsJ2lY+t1N0+PvAhsXlLubpMtKWm7n9ON04Lj02Figd5lYNwGWp4lwG5KWaYsGPlnZ52sk3e93gBclHZ1eQ5J2KnMN64KcDA3gKpL7gXOUvOjolyS9hluB54EnSd7l8bfiL0bEUpL7fFMkPc4n3dTbgcNbBlBI3vMyKh2gmccno9rnAPtKmkPSXX+lTKx3At0kPQGcBzxUcO59YDtJs0nuCZ6bHj8O+HYa31ySpfnN1uBVa8zMcMvQzAxwMjQzA5wMzcwAJ0MzM8DJ0MwMcDI0MwOcDM3MAPj/siq+r2Ss7EoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "disp = plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues,normalize='true');\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a7871946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04423412",
   "metadata": {},
   "source": [
    "Apply 5-fold cv to the SVC classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f22ee916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96 accuracy with a standard deviation of 0.01\n"
     ]
    }
   ],
   "source": [
    "# apply five fold cross validations\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "198faf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98 accuracy with a standard deviation of 0.15\n"
     ]
    }
   ],
   "source": [
    "#apply looc to SVC classifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "looc = LeaveOneOut()\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=looc)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a6688958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e77cee",
   "metadata": {},
   "source": [
    "Let's try applying PCA along with the scaling and SVC algm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e3ad4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "svc = SVC(gamma='auto')\n",
    "pipe = Pipeline(steps=[('pca',pca),('scale',StandardScaler()), ('svc', svc)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "69ddf74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'pca__n_components':[5,10,20],\n",
    "    'svc__C':[0.4,0.6, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69365302",
   "metadata": {},
   "source": [
    "Fit the steps into a pipe and perform hyper-param tuning on validation set using grid-search..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "631be7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.799):\n",
      "{'pca__n_components': 20, 'svc__C': 1}\n"
     ]
    }
   ],
   "source": [
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "search.fit(X_valid, y_valid)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "76082b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7696969696969697\n"
     ]
    }
   ],
   "source": [
    "scr = search.score(X_test, y_test)\n",
    "print(f\"Accuracy {scr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2890a83",
   "metadata": {},
   "source": [
    "Applying an alternative algm classifier such as logistic regression and perform hyper-param tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c565e4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression(random_state=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f77028a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7378048780487805"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7d5a05b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.744):\n",
      "{'log_clf__C': 0.4, 'log_clf__penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.74431818        nan        nan 0.74431818        nan\n",
      "        nan 0.74431818        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logRegClsPipe = Pipeline(steps=[('scale',StandardScaler()), ('log_clf', LogisticRegression())])\n",
    "log_param_grid = {\n",
    "'log_clf__C':[0.4,0.6, 1],\n",
    "'log_clf__penalty':['l1','l2','elasticnet'],\n",
    "}\n",
    "log_GS = GridSearchCV(logRegClsPipe, log_param_grid, n_jobs=-1)\n",
    "log_GS.fit(X_valid, y_valid)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % log_GS.best_score_)\n",
    "print(log_GS.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ea7335e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.806060606060606"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_GS.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207b3417",
   "metadata": {},
   "source": [
    "Lets try applying  the NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "746e9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3b13ffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.841):\n",
      "{'nb_clf__var_smoothing': 0.004}\n",
      "NB Score: 0.8909090909090909\n"
     ]
    }
   ],
   "source": [
    "nbClfPipe = Pipeline(steps=[('scale',StandardScaler()), ('nb_clf', nb_clf)])\n",
    "nb_param_grid = {\n",
    "'nb_clf__var_smoothing':[0.004,1e-5, 1e-09],\n",
    "}\n",
    "nb_GS = GridSearchCV(nbClfPipe, nb_param_grid, n_jobs=-1)\n",
    "nb_GS.fit(X_valid, y_valid)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % nb_GS.best_score_)\n",
    "print(nb_GS.best_params_)\n",
    "print(f\"NB Score: {nb_GS.score(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3e949c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9a3c54dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99        93\n",
      "           1       1.00      0.99      0.99        72\n",
      "\n",
      "    accuracy                           0.99       165\n",
      "   macro avg       0.99      0.99      0.99       165\n",
      "weighted avg       0.99      0.99      0.99       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVC_y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, SVC_y_pred, labels=[-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e0094215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.86      0.81        93\n",
      "           1       0.78      0.65      0.71        72\n",
      "\n",
      "    accuracy                           0.77       165\n",
      "   macro avg       0.77      0.76      0.76       165\n",
      "weighted avg       0.77      0.77      0.77       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_SVC_y_pred = search.predict(X_test)\n",
    "print(classification_report(y_test, pca_SVC_y_pred, labels=[-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5c1e8e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "logCLF_y_pred = log_GS.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a5ad76f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.83      0.83        93\n",
      "           1       0.78      0.78      0.78        72\n",
      "\n",
      "    accuracy                           0.81       165\n",
      "   macro avg       0.80      0.80      0.80       165\n",
      "weighted avg       0.81      0.81      0.81       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, logCLF_y_pred, labels=[-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c090fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      1.00      0.91        93\n",
      "           1       1.00      0.75      0.86        72\n",
      "\n",
      "    accuracy                           0.89       165\n",
      "   macro avg       0.92      0.88      0.88       165\n",
      "weighted avg       0.91      0.89      0.89       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NBCLF_y_pred = nb_GS.predict(X_test)\n",
    "print(classification_report(y_test, NBCLF_y_pred, labels=[-1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564518ab",
   "metadata": {},
   "source": [
    "**As per the classification reports above, the SVC classifier is the best model to use with an f1-score of 94%**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0c828",
   "metadata": {},
   "source": [
    "### Check if for a new sample of data-points the accuracy will vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a8aaf00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# takes a dataset along with a fraction variable of \n",
    "# which to sample the new datapoints\n",
    "def get_sample_data(dataset, frac):\n",
    "    sample = pd.DataFrame()\n",
    "    assert frac>0.0 and frac <1.0,\"frac argument should be between 0 and 1\"\n",
    "    dataset_size = len(dataset)\n",
    "    print(dataset_size)\n",
    "    randomlist = random.sample(range(0, dataset_size), round(float(dataset_size)*float(frac)))\n",
    "    return dataset.iloc[randomlist]\n",
    "\n",
    "#test_df = get_sample_data(X,.22)\n",
    "#test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0c96e39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3044.460000</td>\n",
       "      <td>2497.580000</td>\n",
       "      <td>2178.144400</td>\n",
       "      <td>1074.514500</td>\n",
       "      <td>1.226000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.095600</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>1.371400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.503700</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>3.627000</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>220.321350</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3079.440000</td>\n",
       "      <td>2395.390000</td>\n",
       "      <td>2209.088900</td>\n",
       "      <td>1459.473900</td>\n",
       "      <td>2.161200</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.901100</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>1.533500</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.501700</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>3.663100</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>35.670200</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3015.710000</td>\n",
       "      <td>2531.500000</td>\n",
       "      <td>2204.666700</td>\n",
       "      <td>1078.786000</td>\n",
       "      <td>0.915200</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.961100</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>1.386800</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>3.922900</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>88.136500</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3006.330000</td>\n",
       "      <td>2424.130000</td>\n",
       "      <td>2189.355600</td>\n",
       "      <td>2349.596050</td>\n",
       "      <td>2.141500</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88.049500</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>1.495100</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.902500</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>59.082500</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3047.280000</td>\n",
       "      <td>2324.095000</td>\n",
       "      <td>2235.055600</td>\n",
       "      <td>1302.660700</td>\n",
       "      <td>1.634700</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.985600</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>1.461900</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>2.622900</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>81.947200</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>2967.926749</td>\n",
       "      <td>2551.797794</td>\n",
       "      <td>2182.754839</td>\n",
       "      <td>1010.604457</td>\n",
       "      <td>1.303356</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.375422</td>\n",
       "      <td>0.121769</td>\n",
       "      <td>1.495158</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.500290</td>\n",
       "      <td>0.017042</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>3.403231</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.017518</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>185.067067</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>2999.841254</td>\n",
       "      <td>2396.356248</td>\n",
       "      <td>2223.683114</td>\n",
       "      <td>1506.184269</td>\n",
       "      <td>1.193120</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.380188</td>\n",
       "      <td>0.121169</td>\n",
       "      <td>1.448251</td>\n",
       "      <td>-0.017681</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.504509</td>\n",
       "      <td>0.012213</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>2.428254</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.029376</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>143.907630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>3015.631629</td>\n",
       "      <td>2418.073406</td>\n",
       "      <td>2188.680640</td>\n",
       "      <td>1699.909286</td>\n",
       "      <td>1.110616</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.623948</td>\n",
       "      <td>0.124174</td>\n",
       "      <td>1.522657</td>\n",
       "      <td>-0.011801</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.494033</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>3.056107</td>\n",
       "      <td>0.030254</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>62.058648</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>3003.315167</td>\n",
       "      <td>2453.624695</td>\n",
       "      <td>2184.380242</td>\n",
       "      <td>1596.597894</td>\n",
       "      <td>1.329552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.918544</td>\n",
       "      <td>0.123701</td>\n",
       "      <td>1.465163</td>\n",
       "      <td>-0.010873</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.497228</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>2.543604</td>\n",
       "      <td>0.030180</td>\n",
       "      <td>0.026423</td>\n",
       "      <td>0.008633</td>\n",
       "      <td>89.823048</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>2974.558140</td>\n",
       "      <td>2362.737819</td>\n",
       "      <td>2195.676915</td>\n",
       "      <td>1065.860952</td>\n",
       "      <td>1.203288</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.006862</td>\n",
       "      <td>0.121187</td>\n",
       "      <td>1.449761</td>\n",
       "      <td>-0.006154</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.502112</td>\n",
       "      <td>0.013256</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>2.631574</td>\n",
       "      <td>0.020433</td>\n",
       "      <td>0.012187</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>59.102159</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3         4      5  \\\n",
       "0     3044.460000  2497.580000  2178.144400  1074.514500  1.226000  100.0   \n",
       "1     3079.440000  2395.390000  2209.088900  1459.473900  2.161200  100.0   \n",
       "2     3015.710000  2531.500000  2204.666700  1078.786000  0.915200  100.0   \n",
       "3     3006.330000  2424.130000  2189.355600  2349.596050  2.141500  100.0   \n",
       "4     3047.280000  2324.095000  2235.055600  1302.660700  1.634700  100.0   \n",
       "...           ...          ...          ...          ...       ...    ...   \n",
       "1639  2967.926749  2551.797794  2182.754839  1010.604457  1.303356  100.0   \n",
       "1640  2999.841254  2396.356248  2223.683114  1506.184269  1.193120  100.0   \n",
       "1641  3015.631629  2418.073406  2188.680640  1699.909286  1.110616  100.0   \n",
       "1642  3003.315167  2453.624695  2184.380242  1596.597894  1.329552  100.0   \n",
       "1643  2974.558140  2362.737819  2195.676915  1065.860952  1.203288  100.0   \n",
       "\n",
       "               6         7         8         9  ...      581       582  \\\n",
       "0     101.095600  0.121800  1.371400  0.003700  ...  72.2889  0.503700   \n",
       "1      98.901100  0.124200  1.533500  0.015800  ...  72.2889  0.501700   \n",
       "2     103.961100  0.119600  1.386800  0.018400  ...  72.2889  0.500600   \n",
       "3      88.049500  0.124600  1.495100 -0.004900  ...  72.2889  0.502400   \n",
       "4     109.985600  0.123000  1.461900  0.018900  ...  72.2889  0.499800   \n",
       "...          ...       ...       ...       ...  ...      ...       ...   \n",
       "1639  102.375422  0.121769  1.495158  0.008180  ...  72.2889  0.500290   \n",
       "1640  109.380188  0.121169  1.448251 -0.017681  ...  72.2889  0.504509   \n",
       "1641  102.623948  0.124174  1.522657 -0.011801  ...  72.2889  0.494033   \n",
       "1642  101.918544  0.123701  1.465163 -0.010873  ...  72.2889  0.497228   \n",
       "1643  102.006862  0.121187  1.449761 -0.006154  ...  72.2889  0.502112   \n",
       "\n",
       "           583       584       585       586       587       588         589  \\\n",
       "0     0.018300  0.005300  3.627000  0.005800  0.016900  0.006000  220.321350   \n",
       "1     0.018400  0.004500  3.663100  0.016200  0.005800  0.001900   35.670200   \n",
       "2     0.019600  0.004600  3.922900  0.012800  0.011300  0.003400   88.136500   \n",
       "3     0.009600  0.002500  1.902500  0.047300  0.028000  0.008700   59.082500   \n",
       "4     0.013100  0.003300  2.622900  0.022200  0.018200  0.006000   81.947200   \n",
       "...        ...       ...       ...       ...       ...       ...         ...   \n",
       "1639  0.017042  0.004056  3.403231  0.007885  0.017518  0.005962  185.067067   \n",
       "1640  0.012213  0.003538  2.428254  0.020391  0.029376  0.009335  143.907630   \n",
       "1641  0.015139  0.003845  3.056107  0.030254  0.018909  0.005361   62.058648   \n",
       "1642  0.012675  0.003335  2.543604  0.030180  0.026423  0.008633   89.823048   \n",
       "1643  0.013256  0.004066  2.631574  0.020433  0.012187  0.004403   59.102159   \n",
       "\n",
       "      result  \n",
       "0       -1.0  \n",
       "1       -1.0  \n",
       "2       -1.0  \n",
       "3       -1.0  \n",
       "4       -1.0  \n",
       "...      ...  \n",
       "1639     1.0  \n",
       "1640     1.0  \n",
       "1641     1.0  \n",
       "1642     1.0  \n",
       "1643     1.0  \n",
       "\n",
       "[1644 rows x 591 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = pd.concat([X_bal, y_bal], axis=1)\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "da0a540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644\n"
     ]
    }
   ],
   "source": [
    "sample_dataset = get_sample_data(balanced_df,0.99)\n",
    "X_sample = sample_dataset.drop(columns=['result']).copy()\n",
    "y_sample = sample_dataset['result']\n",
    "X_sample_train,X_sample_test,y_sample_train,y_sample_test = train_test_split(X_bal,y_bal,train_size=train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7bca2d",
   "metadata": {},
   "source": [
    "Lets re-use our selected classifier model for this new sampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f20824e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy old dataset 0.9939393939393939\n",
      "Accuracy new dataset 0.9969604863221885\n"
     ]
    }
   ],
   "source": [
    "scr = clf.score(X_test, y_test)\n",
    "new_sample = clf.score(X_sample_test,y_sample_test)\n",
    "print(f\"Accuracy old dataset {scr}\")\n",
    "print(f\"Accuracy new dataset {new_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a92cf6",
   "metadata": {},
   "source": [
    "There is only negligible difference in the accuracy score among the original dataset and the resampled dataset. However, generally we might see a difference in the accuracy when data-points are resampled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3938f96",
   "metadata": {},
   "source": [
    "### Save and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5d8a829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'FMT_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "40fd0cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9939393939393939\n"
     ]
    }
   ],
   "source": [
    "#Load the saved model and display prediction results\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c117bd43",
   "metadata": {},
   "source": [
    "###  Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ce741",
   "metadata": {},
   "source": [
    "Feature selection and model tuning helps us to optimize the dataset for ML algorithms. Further, cross-validations allow us to average out the performance of the model on the dataset and ensure there is less variance in the score. Cross-validations along with splitting into train,test and validation datasets gives us a confidence in the estimates we can expect in real world data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
